---
title: "A Survey of Optimization Methods from a Machine Learning Perspective(ì§„í–‰ì¤‘)"
date: 2025-08-28 13:00:00 +0900
categories: [AI-ML-DL, etc.]
tags: [paper, Computer-Vision, optimizer]
---

# A Survey of Optimization Methods from a Machine Learning Perspective

---

### ğŸ”—Â ì¶œì²˜

> https://arxiv.org/abs/1906.06821
> 

---

### ğŸ“¦Â ì¶”ê°€ ìë£Œ

â€¦

## ğŸ§©Â ë°©ë²•ë¡ 

> **by â€¦**
> 

<aside>

</aside>

---

# ğŸ“ŒÂ ë…¼ë¬¸

## ğŸ’¡Â ìš”ì•½

> **by â€¦**
> 

<aside>

</aside>

---

## ğŸ“šÂ ì •ë¦¬

### ğŸ“ŒÂ ì œëª©

<aside>

## A Survey of Optimization Methods from a Machine Learning Perspective

</aside>

---

### ğŸŒŸÂ ì´ˆë¡

### ë²ˆì—­

ì›ë¬¸

Abstractâ€”Machine learning develops rapidly, which has made many theoretical breakthroughs and is widely applied in various fields. Optimization, as an important part of machine learning, has attracted much attention of researchers. With the exponential growth of data amount and the increase of model complexity, optimization methods in machine learning face more and more challenges. A lot of work on solving optimization problems or improving optimization methods in machine learning has been proposed successively. The systematic retrospect and summary of the optimization methods from the perspective of machine learning are of great significance, which can offer guidance for both developments of optimization and machine learning research. In this paper, we first describe the optimization problems in machine learning. Then, we introduce the principles and progresses of commonly used optimization methods. Next, we summarize the applications and developments of optimization methods in some popular machine learning fields. Finally, we explore and give some challenges and open problems for the optimization in machine learning.

Index Termsâ€”Machine learning, optimization method, deep neural network, reinforcement learning, approximate Bayesian inference.

---

ë²ˆì—­ë¬¸

ì´ˆë¡â€”ë¨¸ì‹ ëŸ¬ë‹(Machine Learning)ì€ ë¹ ë¥´ê²Œ ë°œì „í•˜ë©°, ë§ì€ ì´ë¡ ì  ëŒíŒŒêµ¬ë¥¼ ë§Œë“¤ì—ˆê³  ë‹¤ì–‘í•œ ë¶„ì•¼ì— ë„ë¦¬ ì ìš©ë˜ê³  ìˆë‹¤. ë¨¸ì‹ ëŸ¬ë‹ì˜ ì¤‘ìš”í•œ êµ¬ì„± ìš”ì†Œì¸ **ìµœì í™”(Optimization)** ëŠ” ì—°êµ¬ìë“¤ì˜ ë§ì€ ê´€ì‹¬ì„ ë°›ì•„ì™”ë‹¤. ë°ì´í„° ì–‘ì˜ ê¸°í•˜ê¸‰ìˆ˜ì  ì¦ê°€ì™€ ëª¨ë¸ ë³µì¡ì„±ì˜ ìƒìŠ¹ìœ¼ë¡œ ì¸í•´, ë¨¸ì‹ ëŸ¬ë‹ì˜ ìµœì í™” ê¸°ë²•ì€ ì ì  ë” ë§ì€ ë„ì „ì— ì§ë©´í•˜ê³  ìˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê±°ë‚˜ ìµœì í™” ë°©ë²•ì„ ê°œì„ í•˜ë ¤ëŠ” ë§ì€ ì—°êµ¬ê°€ ì‡ë‹¬ì•„ ì œì•ˆë˜ì–´ ì™”ë‹¤. ë¨¸ì‹ ëŸ¬ë‹ ê´€ì ì—ì„œ ìµœì í™” ë°©ë²•ì„ ì²´ê³„ì ìœ¼ë¡œ íšŒê³ í•˜ê³  ì •ë¦¬í•˜ëŠ” ê²ƒì€ ìµœì í™”ì™€ ë¨¸ì‹ ëŸ¬ë‹ ì—°êµ¬ì˜ ë°œì „ ëª¨ë‘ì— ì¤‘ìš”í•œ ì§€ì¹¨ì„ ì œê³µí•œë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ë¨¼ì € ë¨¸ì‹ ëŸ¬ë‹ì—ì„œì˜ ìµœì í™” ë¬¸ì œë¥¼ ì„¤ëª…í•œë‹¤. ì´í›„, ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ìµœì í™” ê¸°ë²•ë“¤ì˜ ì›ë¦¬ì™€ ë°œì „ì„ ì†Œê°œí•œë‹¤. ë‹¤ìŒìœ¼ë¡œ, ì¸ê¸° ìˆëŠ” ë¨¸ì‹ ëŸ¬ë‹ ë¶„ì•¼ì—ì„œ ìµœì í™” ê¸°ë²•ì˜ ì‘ìš© ë° ë°œì „ì„ ì •ë¦¬í•œë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ë¨¸ì‹ ëŸ¬ë‹ ìµœì í™”ì—ì„œì˜ **ë„ì „ ê³¼ì œ(challenges)ì™€ ë¯¸í•´ê²° ë¬¸ì œ(open problems)** ë¥¼ íƒêµ¬í•˜ê³  ì œì‹œí•œë‹¤.

ìƒ‰ì¸ì–´â€”ë¨¸ì‹ ëŸ¬ë‹(Machine learning), ìµœì í™” ê¸°ë²•(Optimization method), ì‹¬ì¸µ ì‹ ê²½ë§(Deep Neural Network), ê°•í™”í•™ìŠµ(Reinforcement Learning), ê·¼ì‚¬ ë² ì´ì§€ì•ˆ ì¶”ë¡ (Approximate Bayesian Inference).

<aside>

# 0. Abstract

- ìµœì í™” ê¸°ë²• ì„œë² ì´ ë…¼ë¬¸
    - ë„ì „ ê³¼ì œ
    - ë¯¸í•´ê²° ë¬¸ì œë¥¼ ì œì‹œ
</aside>

---

### ğŸ’¡Â ê²°ë¡  & ê³ ì°°

### ë²ˆì—­

1. ì›ë¬¸ (ìš”ì•½ëœ ê²°ë¡  ë° ê³ ì°° ë¶€ë¶„)
    
    The development of optimization brings a lot of contributions to the progress of machine learning. However, there are still many challenges and open problems for optimization problems in machine learning.
    
    1. How to improve optimization performance with insufficient data in deep neural networks is a tricky problemâ€¦
    2. For sequential models, the samples are often truncated by batches when the sequence is too long, which will cause deviationâ€¦
    3. The stochastic variational inference is graceful and practical, and it is probably a good choice to develop methods of applying high-order gradient informationâ€¦
    4. It may be a great idea to introduce the stochastic technique to the conjugate gradient method to obtain an elegant and powerful optimization algorithmâ€¦
    
    The purpose of this paper is to summarize and analyze classical and modern optimization methods from a machine learning perspective. Firstly, we describe the theoretical basisâ€¦ Then we describe the applicationsâ€¦ Finally, we discuss some challenges and open problemsâ€¦
    

---

1. ë²ˆì—­ë¬¸
    
    ìµœì í™”(Optimization)ì˜ ë°œì „ì€ ë¨¸ì‹ ëŸ¬ë‹ì˜ ì§„ë³´ì— ë§ì€ ê¸°ì—¬ë¥¼ í•´ì™”ë‹¤. ê·¸ëŸ¬ë‚˜ ì—¬ì „íˆ ë¨¸ì‹ ëŸ¬ë‹ì˜ ìµœì í™” ë¬¸ì œì—ëŠ” ë§ì€ **ë„ì „ ê³¼ì œ(challenges)ì™€ ë¯¸í•´ê²° ë¬¸ì œ(open problems)** ê°€ ë‚¨ì•„ ìˆë‹¤.
    
    1. **ë°ì´í„° ë¶€ì¡± ìƒí™©ì—ì„œ ì‹¬ì¸µ ì‹ ê²½ë§(Deep Neural Network, DNN)ì˜ ìµœì í™” ì„±ëŠ¥ì„ í–¥ìƒ**ì‹œí‚¤ëŠ” ê²ƒì€ ì–´ë ¤ìš´ ë¬¸ì œì´ë‹¤. ìƒ˜í”Œ ìˆ˜ê°€ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ ê³ ë¶„ì‚°(high variance)ê³¼ ê³¼ì í•©(overfitting)ì´ ë°œìƒí•˜ê¸° ì‰½ë‹¤. ë˜í•œ, DNN í•™ìŠµì—ì„œ ë¹„ë³¼ë¡(non-convex) ìµœì í™” ë¬¸ì œëŠ” ì „ì—­ ìµœì í•´(global optimum)ê°€ ì•„ë‹Œ êµ­ì†Œ ìµœì í•´(local optimum)ì— ë¹ ì§ˆ ìœ„í—˜ì´ ìˆë‹¤.
    2. **ìˆœì°¨ì  ëª¨ë¸(sequential models)** ì˜ ê²½ìš°, ì‹œí€€ìŠ¤ê°€ ë„ˆë¬´ ê¸¸ë©´ ì¼ë°˜ì ìœ¼ë¡œ ë¯¸ë‹ˆë°°ì¹˜ ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ ì²˜ë¦¬í•œë‹¤. ì´ë•Œ ìƒ˜í”Œì´ ì˜ë¦¬ë©´ì„œ **í¸í–¥(deviation)** ì´ ë°œìƒí•  ìˆ˜ ìˆëŠ”ë°, ì´ë¥¼ ì–´ë–»ê²Œ ë¶„ì„í•˜ê³  ìˆ˜ì •í• ì§€ê°€ ì¤‘ìš”í•˜ë‹¤.
    3. **í™•ë¥ ì  ë³€ë¶„ ì¶”ë¡ (Stochastic Variational Inference, SVI)** ì€ ìš°ì•„í•˜ê³  ì‹¤ìš©ì ì¸ ì ‘ê·¼ë²•ì´ë©°, ì—¬ê¸°ì— ê³ ì°¨ ë„í•¨ìˆ˜(high-order gradient) ì •ë³´ë¥¼ ì ìš©í•˜ëŠ” ë°©ë²•ì„ ê°œë°œí•˜ëŠ” ê²ƒì´ ìœ ë§í•˜ë‹¤.
    4. **í™•ë¥ ì  ê¸°ë²•(stochastic techniques)ì„ ê³µì•¡ê¸°ìš¸ê¸°ë²•(Conjugate Gradient Method)** ì— ì ‘ëª©í•˜ëŠ” ê²ƒë„ ìš°ì•„í•˜ê³  ê°•ë ¥í•œ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì„ ì–»ëŠ” ë°©ë²•ì´ ë  ìˆ˜ ìˆë‹¤.
    
    ì´ ë…¼ë¬¸ì˜ ëª©ì ì€ ë¨¸ì‹ ëŸ¬ë‹ ê´€ì ì—ì„œ **ê³ ì „ì (classical) ë° í˜„ëŒ€ì (modern) ìµœì í™” ê¸°ë²•ì„ ìš”ì•½Â·ë¶„ì„**í•˜ëŠ” ë° ìˆë‹¤. ìš°ì„  ì´ë¡ ì  ê¸°ë°˜ì„ ë‹¤ë£¨ì—ˆê³ , ì´ì–´ì„œ ë‹¤ì–‘í•œ ìµœì í™” ê¸°ë²•ë“¤ì˜ ì‘ìš©ì„ ì„¤ëª…í•˜ì˜€ìœ¼ë©°, ë§ˆì§€ë§‰ìœ¼ë¡œ í–¥í›„ ì—°êµ¬ë¥¼ ìœ„í•œ **ë„ì „ ê³¼ì œì™€ ì˜¤í”ˆ ë¬¸ì œ**ë“¤ì„ ì œì‹œí•˜ì˜€ë‹¤.
    

<aside>

# 6. ê²°ë¡ 

- ìµœì í™” ë¬¸ì œì˜ ë„ì „ê³¼ì œ
    - **ë°ì´í„° ë¶€ì¡± ìƒí™©ì—ì„œì˜ DNN ìµœì í™”ì™€ ì„±ëŠ¥ í–¥ìƒ : ìƒ˜í”Œ ìˆ˜ê°€ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ ê³ ë¶„ì‚°ê³¼ ê³¼ì í•©ì´ ë°œìƒí•˜ê¸° ì‰½ë‹¤**. ë˜í•œ **non-convex ìµœì í™” ë¬¸ì œëŠ” global optimumì´ì•„ë‹ˆë¼ local optimumì— ë¹ ì§ˆ ìœ„í—˜**ì´ ìˆë‹¤.
    - **Sequentail models :** ì‹œí€€ìŠ¤ê°€ ë„ˆë¬´ ê¸¸ë©´ **ë¯¸ë‹ˆ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ ì²˜ë¦¬í•˜ëŠ”ë° ì´ë•Œ ìƒ˜í”Œì´ ì˜ë¦¬ë©´ì„œ deviation(í¸í–¥)ì´ ë°œìƒ** í•  ìˆ˜ ìˆë‹¤.
    - **Stochastic Variational Inferecne(SVI, í™•ë¥ ì  ë³€ë¶„ ì¶”ë¡ )** : ì‹¤ìš©ì ì¸ ì ‘ê·¼ë²•ì´ë©°, ê³ ì°¨ ë„í•¨ìˆ˜ë¥¼ ì ìš©í•˜ëŠ” ë°©ë²•ì„ ê°œë°œí•˜ëŠ”ê²ƒì´ ìœ ë§í•˜ë‹¤.
    - **Stochastic Techniques(í™•ë¥ ì  ê¸°ë²•), Conjugate Gradient Method(ê³µì•¡ê¸°ìš¸ê¸°ë²•)** : ë˜í•œ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì„ ì–»ëŠ” ìœ ë§í•œ ë°©ë²•ì´ë‹¤.

<aside>

### í™•ë¥ ì  ë³€ë¶„ ì¶”ë¡  (Stochastic Variational Inference, SVI)

ë³µì¡í•œ í™•ë¥  ëª¨ë¸ì—ì„œ **ê·¼ì‚¬ì ì¸ ì¶”ë¡ **ì„ ë¹ ë¥´ê³  íš¨ìœ¨ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, ë¶„ì„ì ìœ¼ë¡œ ê³„ì‚°í•˜ê¸° ì–´ë ¤ìš´ ì‚¬í›„ ë¶„í¬(posterior dist.)ë¥¼ ë‹¤ë£° ë•Œ ìœ ìš©í•˜ë‹¤. ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì— íš¨ê³¼ì ìœ¼ë¡œ ì ìš©í•  ìˆ˜ ìˆë‹¤.

- í•µì‹¬ ì•„ì´ë””ì–´ : ë‹¤ë£¨ê¸° í˜ë“  ì‹¤ì œ **ì‚¬í›„ë¶„í¬ë¥¼ ë‹¤ë£¨ê¸° ì‰¬ìš´ ê°„ë‹¨í•œ ê·¼ì‚¬ë¶„í¬ë¡œ ëŒ€ì²´**í•˜ëŠ”ë° **ì¼ë°˜ì ìœ¼ë¡œ KL-divergenceë¥¼ ìµœì†Œí™”í•˜ëŠ” ë°©í–¥**ì„ ì°¾ëŠ”ê²ƒì„
- **í™•ë¥ ì  :** ì „ì²´ ë°ì´í„° ì¤‘ ì¼ë¶€ë¥¼ ì¦‰ ë¯¸ë‹ˆë°°ì¹˜ë§Œì„ ë¬´ì‘ìœ„ë¡œ ìƒ˜í”Œë§í•˜ì—¬ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ”ë° ì´ëŠ” SGDë‘ ë¹„ìŠ·í•˜ë‹¤.
- **ê³ ì°¨ ë„í•¨ìˆ˜ ì ìš©ì˜ ìœ ë§ì„±** : ì¼ë°˜ì ìœ¼ë¡œ **SVIëŠ” ê²½ì‚¬ ê¸°ë°˜ ìµœì í™”ë¥¼ ìˆ˜í–‰**í•˜ëŠ”ë°, **í—¤ì‹ ê±°ë¦¬ì™€ ê°™ì€ 2ì°¨ ë„í•¨ìˆ˜ ì •ë³´ë¥¼ í™œìš©í•˜ê²Œ ëœë‹¤ë©´ ì†ì‹¤ í•¨ìˆ˜ì˜ ê³¡ë¥ ê¹Œì§€ ê³ ë ¤**í•  ìˆ˜ ìˆì–´ í›¨ì”¬ ë” ë¹ ë¥´ê³  ì•ˆì •ì ì¸ ìˆ˜ë ´ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŒ. ì´ëŠ” ë‰´í„´ ë°©ë²•ì´ ê²½ì‚¬ í•˜ê°•ë²•ë³´ë‹¤ ë” ë¹ ë¥´ê²Œ ìµœì ì ì— ë„ë‹¬í•˜ëŠ”ê²ƒê³¼ ë™ì¼í•˜ë‹¤.
</aside>

<aside>

### í™•ë¥ ì  ê¸°ë²• (Stochastic Techniques)

ì•Œê³ ë¦¬ì¦˜ ì¼ë¶€ ê³¼ì •ì— **ë¬´ì‘ìœ„ì„±**ì„ ë„ì…í•˜ëŠ” ëª¨ë“  ë°©ë²•ì„ í¬ê´„í•œë‹¤. ì´ëŠ” ëŒ€ê·œëª¨ ë¬¸ì œë‚˜ ì¡ìŒì´ ë§ì€ ë°ì´í„°ë¥¼ ë‹¤ë£° ë•Œ íš¨ê³¼ì ì´ë‹¤. ê²°ì •ë¡ ì  ë°©ë²•ì€ ì¼ì •í•œ ê²½ë¡œë¡œ í•´ë¥¼ ì°¾ì•„ê°€ëŠ”ê²ƒê³¼ ë‹¬ë¦¬, í™•ë¥ ì  ë°©ë²•ì€ local optimaì— ë¹ ì§€ëŠ”ê²ƒì„ ë°©ì§€í•˜ê³  global optimaë¥¼ ì°¾ì„ ê°€ëŠ¥ì„±ì„ ë†’ì—¬ì¤€ë‹¤.

**ì£¼ìš” ì˜ˆì‹œ**:

- **í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²• (SGD)**: ì „ì²´ ë°ì´í„°ê°€ ì•„ë‹Œ ë¯¸ë‹ˆë°°ì¹˜ë¥¼ ë¬´ì‘ìœ„ë¡œ ë½‘ì•„ ê²½ì‚¬ë¥¼ ê³„ì‚°í•˜ê³  ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ê°€ì¥ ëŒ€í‘œì ì¸ í™•ë¥ ì  ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.
- **ëª¬í…Œì¹´ë¥¼ë¡œ ë°©ë²• (Monte Carlo Methods)**: ë¬´ì‘ìœ„ ìƒ˜í”Œë§ì„ í†µí•´ ì ë¶„ì´ë‚˜ í™•ë¥  ë¶„í¬ ê³„ì‚° ë“± ì–´ë ¤ìš´ ìˆ˜ì¹˜ ê³„ì‚°ì„ ê·¼ì‚¬ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.
- **ì‹œë®¬ë ˆì´í‹°ë“œ ì–´ë‹ë§ (Simulated Annealing)**: ë‹´ê¸ˆì§ˆ ê³¼ì •ì—ì„œ ì˜ê°ì„ ì–»ì€ ìµœì í™” ë°©ë²•ìœ¼ë¡œ, í™•ë¥ ì ìœ¼ë¡œ í˜„ì¬ í•´ë³´ë‹¤ ì¢‹ì§€ ì•Šì€ í•´ë¥¼ ì„ íƒí•  ìˆ˜ë„ ìˆì–´ ì§€ì—­ ìµœì ì ì„ íƒˆì¶œí•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.
- **ìœ ì „ ì•Œê³ ë¦¬ì¦˜ (Genetic Algorithms)**: ìƒë¬¼ì˜ ì§„í™” ê³¼ì •ì„ ëª¨ë°©í•œ íƒìƒ‰ ê¸°ë²•ìœ¼ë¡œ, ì„ íƒ, êµë°°, ëŒì—°ë³€ì´ ë“± í™•ë¥ ì  ì—°ì‚°ì„ í†µí•´ í•´ë¥¼ ê°œì„ í•´ ë‚˜ê°‘ë‹ˆë‹¤.
</aside>

<aside>

### ê³µì•¡ ê¸°ìš¸ê¸°ë²• (Conjugate Gradient Method)

**ì£¼ë¡œ ì„ í˜•ë¬¸ì œë‚˜, ì´ì°¨ í˜•ì‹ì˜ í•¨ìˆ˜ë¥¼ ìµœì í™”í•˜ëŠ”ë° ì‚¬ìš©ë˜ëŠ” íš¨ìœ¨ì ì¸ ë°˜ë³µ ì•Œê³ ë¦¬ì¦˜ì„**

- í•µì‹¬ ì•„ì´ë””ì–´ : ì¼ë°˜ì ì¸ ê²½ì‚¬ í•˜ê°•ë²•ì€ í˜„ì¬ ìœ„ì¹˜ì—ì„œ ê°€ì¥ ê°€íŒŒë¥¸ ë°©í–¥ìœ¼ë¡œë§Œ ì´ë™í•œë‹¤. ì´ ë•Œë¬¸ì— ì§„í–‰í–ˆë–¤ ë°©í–¥ì˜ íƒìƒ‰ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ë¬´íš¨ë¡œ í•˜ëŠ” ì§€ê·¸ì¬ê·¸ ì›€ì§ì„ì„ ë³´ì¼ ìˆ˜ ìˆëŠ”ë°, ê³µì•¡ ê¸°ìš¸ê¸°ë²•ì€ ê³µì•¡ì´ë¼ëŠ” íŠ¹ë³„í•œ ì„±ì§ˆì„ ë§Œì¡±í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ íƒì§€ë¥¼ ì§„í–‰í•˜ë©°, **í•œë²ˆ ì´ë™í•˜ë©´ ê·¸ ë°©í–¥ìœ¼ë¡œëŠ” ë” ì´ìƒ ìµœì í™”í•  í•„ìš”ê°€ ì—†ë‹¤ëŠ”ê²ƒì´ ë³´ì¥**ëœë‹¤.
- ì›ë¦¬
    1. ê°€ì¥ ê°€íŒŒë¥¸ ê²½ì‚¬í•˜ê°•ìœ¼ë¡œ ì²˜ìŒ ì´ë™
    2. ë‹¤ìŒ ì´ë™ë¶€í„°ëŠ” ì´ì „ì˜ ê¸°ìš¸ê¸° ì •ë³´ë¥¼ í™œìš©í•˜ì—¬, ì´ì „ íƒìƒ‰ ë°©í–¥ê³¼ ê³µì•¡ ê´€ê³„ì— ìˆëŠ” ìƒˆë¡œìš´ íƒìƒ‰ ë°©í–¥ì„ ë§Œë“ ë‹¤
    3. ì´ ê³¼ì •ì„ ë°˜ë³µí•œë‹¤. ìµœì•…ì€ Në²ˆì´ë‹¤.
- ë¹„ì„ í˜• ê³µì•¡ ê¸°ìš¸ê¸°ë²•ë„ ê²½ì‚¬ í•˜ê°•ë²• ë³´ë‹¤ í›¨ì”¬ íš¨ìœ¨ì ì¸ ëŒ€ì•ˆìœ¼ë¡œ ì‚¬ìš©ëœë‹¤.
</aside>

### âœ… 5ì¤„ ìš”ì•½

- ìµœì í™”ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ì„±ëŠ¥ í–¥ìƒì˜ í•µì‹¬ ë™ë ¥.
- **ë°ì´í„° ë¶€ì¡± + DNNì˜ ë¹„ë³¼ë¡(non-convex) êµ¬ì¡°** â†’ ì—¬ì „íˆ í° ë‚œì œ.
- ìˆœì°¨ ëª¨ë¸ì€ **ë°°ì¹˜ ë‹¨ìœ„ ì²˜ë¦¬ë¡œ ì¸í•œ í¸í–¥ ë¬¸ì œ** ì¡´ì¬.
- **SVI + ê³ ì°¨ ì •ë³´** ê²°í•©ì€ í–¥í›„ ì¤‘ìš”í•œ ì—°êµ¬ ë°©í–¥.
- **Stochastic Conjugate Gradient** ëŠ” ìš°ì•„í•˜ë©´ì„œë„ ê°•ë ¥í•œ ìƒˆë¡œìš´ ìµœì í™”ë²•ìœ¼ë¡œ ì£¼ëª©.

ğŸ“Œ ì£¼ìš” í¬ì¸íŠ¸

| í•­ëª©                 | ë‚´ìš©                                                                                                                                                  |
| -------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------- |
| Convex vs Non-convex | â€¢ Convex ë¬¸ì œì—ì„œëŠ” ê¸°ì¡´ ê¸°ë²•(Gradient Descent, Newton ë“±)ìœ¼ë¡œ ì „ì—­ ìµœì í•´ ë³´ì¥â€¢ DNN, RL ë“±ì€ ëŒ€ë¶€ë¶„ Non-convex â†’ ì§€ì—­ ìµœì í•´ ìœ„í—˜, saddle point ë¬¸ì œ |
| ë°ì´í„°ì…‹ ë¬¸ì œ        | **ë°ì´í„° ë¶€ì¡±** ì‹œ DNNì€ ê³¼ì í•©Â·ë¶„ì‚° ì¦ê°€ â†’ Transfer Learning, Meta Learning ê°™ì€ ì ‘ê·¼ í•„ìš”                                                           |
| ëª¨ë¸ êµ¬ì¡°            | Sequential models (RNN, LSTM ë“±)ì—ì„œ batch truncationì´ ìµœì í™” ì„±ëŠ¥ì— ì§ì ‘ ì˜í–¥                                                                       |
| í•™ìŠµ ë°©ë²•            | Variational InferenceëŠ” í™•ë¥ ì  ìµœì í™”ì™€ ê²°í•©í•´ì•¼ í™•ì¥ì„± í™•ë³´Conjugate Gradientì— stochastic ê¸°ë²• ì ‘ëª©ì€ ìƒˆë¡œìš´ ì—°êµ¬ ë°©í–¥                              |
| ê²°ê³¼ í•´ì„            | ìµœì í™” ê¸°ë²•ì´ ML ë°œì „ì„ ê²¬ì¸í–ˆì§€ë§Œ, **ëŒ€ê·œëª¨ ë¹„ë³¼ë¡ ë¬¸ì œ, ê³ ì°¨ ì •ë³´ í™œìš©, í™•ë¥ ì  ìµœì í™” ê²°í•©**ì´ í–¥í›„ ì—°êµ¬ ê³¼ì œ                                       |
</aside>

---

### ğŸ“ŒÂ ì„œë¡ 

### ë²ˆì—­

1. ì›ë¬¸ (Introduction ë°œì·Œ)

RECENTLY, machine learning has grown at a remarkable rate, attracting a great number of researchers and practitioners. It has become one of the most popular research directions and plays a significant role in many fields, such as machine translation, speech recognition, image recognition, recommendation system, etc. Optimization is one of the core components of machine learning. The essence of most machine learning algorithms is to build an optimization model and learn the parameters in the objective function from the given data. In the era of immense data, the effectiveness and efficiency of the numerical optimization algorithms dramatically influence the popularization and application of the machine learning models. In order to promote the development of machine learning, a series of effective optimization methods were put forward, which have improved the performance and efficiency of machine learning methods.

From the perspective of the gradient information in optimization, popular optimization methods can be divided into three categories: first-order optimization methods, which are represented by the widely used stochastic gradient methods; high-order optimization methods, in which Newtonâ€™s method is a typical example; and heuristic derivative-free optimization methods, in which the coordinate descent method is a representative.

As the representative of first-order optimization methods, the stochastic gradient descent method, as well as its variants, has been widely used in recent years and is evolving at a high speed. However, many users pay little attention to the characteristics or application scope of these methods. They often adopt them as black box optimizers, which may limit the functionality of the optimization methods. In this paper, we comprehensively introduce the fundamental optimization methods. Particularly, we systematically explain their advantages and disadvantages, their application scope, and the characteristics of their parameters.

Compared with first-order optimization methods, high-order methods converge at a faster speed in which the curvature information makes the search direction more effective. High-order optimizations attract widespread attention but face more challenges. The difficulty in high-order methods lies in the operation and storage of the inverse matrix of the Hessian matrix. To solve this problem, many variants based on Newtonâ€™s method have been developed, most of which try to approximate the Hessian matrix through some techniques.

Derivative-free optimization methods are mainly used in the case that the derivative of the objective function may not exist or be difficult to calculate. There are two main ideas in derivative-free optimization methods. One is adopting a heuristic search based on empirical rules, and the other is fitting the objective function with samples. Derivative-free optimization methods can also work in conjunction with gradient-based methods.

---

1. ë²ˆì—­ë¬¸

ìµœê·¼ ë¨¸ì‹ ëŸ¬ë‹(Machine Learning)ì€ ëˆˆì— ë„ëŠ” ì†ë„ë¡œ ì„±ì¥í•˜ì—¬ ë§ì€ ì—°êµ¬ìì™€ ì‹¤ë¬´ìë“¤ì„ ëŒì–´ë“¤ì´ê³  ìˆë‹¤. ë¨¸ì‹ ëŸ¬ë‹ì€ ì˜¤ëŠ˜ë‚  ê°€ì¥ ì¸ê¸° ìˆëŠ” ì—°êµ¬ ë¶„ì•¼ ì¤‘ í•˜ë‚˜ê°€ ë˜ì—ˆìœ¼ë©°, ê¸°ê³„ë²ˆì—­(Machine Translation), ìŒì„± ì¸ì‹(Speech Recognition), ì´ë¯¸ì§€ ì¸ì‹(Image Recognition), ì¶”ì²œ ì‹œìŠ¤í…œ(Recommendation System) ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ ìˆ˜í–‰í•œë‹¤.

ë¨¸ì‹ ëŸ¬ë‹ì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œ ì¤‘ í•˜ë‚˜ê°€ **ìµœì í™”(Optimization)** ì´ë‹¤. ëŒ€ë¶€ë¶„ì˜ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì˜ ë³¸ì§ˆì€ ìµœì í™” ëª¨ë¸ì„ ì„¸ìš°ê³ , ì£¼ì–´ì§„ ë°ì´í„°ë¡œë¶€í„° ëª©ì í•¨ìˆ˜(Objective Function)ì˜ ë§¤ê°œë³€ìˆ˜(parameter)ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒì´ë‹¤. ê±°ëŒ€ ë°ì´í„° ì‹œëŒ€ì—ëŠ” ìˆ˜ì¹˜ì  ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì˜ íš¨ê³¼ì„±ê³¼ íš¨ìœ¨ì„±ì´ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ ë³´ê¸‰ê³¼ ì‘ìš©ì— ì§ì ‘ì ìœ¼ë¡œ í° ì˜í–¥ì„ ë¯¸ì¹œë‹¤. ì´ëŸ¬í•œ ì´ìœ ë¡œ ë¨¸ì‹ ëŸ¬ë‹ ë°œì „ì„ ì´‰ì§„í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ íš¨ìœ¨ì ì¸ ìµœì í™” ë°©ë²•ë“¤ì´ ì œì•ˆë˜ì–´ ì™”ê³ , ì´ë“¤ì€ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„ í¬ê²Œ ê°œì„ ì‹œì¼°ë‹¤.

ìµœì í™”ì—ì„œ ì‚¬ìš©ë˜ëŠ” **ê¸°ìš¸ê¸°(gradient) ì •ë³´**ì˜ ê´€ì ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ë°©ë²•ë“¤ì€ ì„¸ ê°€ì§€ë¡œ êµ¬ë¶„ëœë‹¤.

1. **1ì°¨ ìµœì í™” ê¸°ë²•(First-order optimization methods)**: í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•(Stochastic Gradient Descent, SGD) ê³„ì—´ì´ ëŒ€í‘œì ì´ë‹¤.
2. **ê³ ì°¨ ìµœì í™” ê¸°ë²•(High-order optimization methods)**: ë‰´í„´ë²•(Newtonâ€™s method)ì´ ì „í˜•ì ì¸ ì˜ˆì´ë‹¤. ê³¡ë¥ (curvature) ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ íƒìƒ‰ ë°©í–¥ì„ ë” íš¨ê³¼ì ìœ¼ë¡œ ë§Œë“ ë‹¤.
3. **ë¬´ë„í•¨ìˆ˜ ìµœì í™” ê¸°ë²•(Derivative-free optimization methods)**: ëª©ì  í•¨ìˆ˜ì˜ ë„í•¨ìˆ˜ê°€ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ê³„ì‚°í•˜ê¸° ì–´ë ¤ìš¸ ë•Œ ì‚¬ìš©ë˜ë©°, ì¢Œí‘œ í•˜ê°•ë²•(Coordinate Descent)ì´ ëŒ€í‘œì ì´ë‹¤.

ì´ ì¤‘ 1ì°¨ ìµœì í™” ê¸°ë²•ì„ ëŒ€í‘œí•˜ëŠ” SGDì™€ ê·¸ ë³€í˜•ë“¤ì€ ìµœê·¼ ìˆ˜ë…„ê°„ í­ë„“ê²Œ ì‚¬ìš©ë˜ë©° ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆë‹¤. ê·¸ëŸ¬ë‚˜ ë§ì€ ì‚¬ìš©ìë“¤ì€ ì´ ê¸°ë²•ë“¤ì˜ íŠ¹ì„±ì´ë‚˜ ì ìš© ë²”ìœ„ì— ì£¼ì˜ë¥¼ ê¸°ìš¸ì´ì§€ ì•Šê³ , **ë¸”ë™ë°•ìŠ¤ ìµœì í™” ë„êµ¬(black box optimizers)** ë¡œì„œ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì—, ìµœì í™” ë°©ë²•ì˜ ê¸°ëŠ¥ì  ì ì¬ë ¥ì„ ì œí•œí•˜ëŠ” ê²½ìš°ê°€ ìˆë‹¤. ë”°ë¼ì„œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ê¸°ì´ˆì ì¸ ìµœì í™” ê¸°ë²•ë“¤ì„ í¬ê´„ì ìœ¼ë¡œ ì†Œê°œí•˜ê³ , ê°ê°ì˜ ì¥ë‹¨ì , ì ìš© ê°€ëŠ¥ ë²”ìœ„, ë§¤ê°œë³€ìˆ˜ íŠ¹ì„±ì„ ì²´ê³„ì ìœ¼ë¡œ ì„¤ëª…í•œë‹¤.

ê³ ì°¨ ìµœì í™” ê¸°ë²•ì€ 1ì°¨ ê¸°ë²•ë³´ë‹¤ ë” ë¹ ë¥¸ ìˆ˜ë ´ ì†ë„ë¥¼ ê°€ì§€ì§€ë§Œ, Hessian í–‰ë ¬ì˜ ì—­í–‰ë ¬ì„ ê³„ì‚°Â·ì €ì¥í•´ì•¼ í•˜ëŠ” ì–´ë ¤ì›€ì´ ìˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë‰´í„´ë²•ì„ ë³€í˜•í•œ ë‹¤ì–‘í•œ ë°©ë²•ë“¤ì´ ê°œë°œë˜ì—ˆìœ¼ë©°, ëŒ€ë¶€ë¶„ Hessianì„ ê·¼ì‚¬(approximate)í•˜ëŠ” ë°©ì‹ì„ ì±„íƒí•œë‹¤.

ë§ˆì§€ë§‰ìœ¼ë¡œ, ë¬´ë„í•¨ìˆ˜ ìµœì í™” ê¸°ë²•ì€ ëª©ì  í•¨ìˆ˜ì˜ ë„í•¨ìˆ˜ê°€ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ê³„ì‚°ì´ ì–´ë ¤ìš¸ ë•Œ ì£¼ë¡œ ì‚¬ìš©ëœë‹¤. ì´ ë°©ë²•ì—ëŠ” ê²½í—˜ì  ê·œì¹™ì— ê¸°ë°˜í•œ **íœ´ë¦¬ìŠ¤í‹± íƒìƒ‰(heuristic search)** ê³¼ í‘œë³¸(sample)ì„ ì´ìš©í•˜ì—¬ ëª©ì  í•¨ìˆ˜ë¥¼ ê·¼ì‚¬í•˜ëŠ” ë°©ë²•ì´ ìˆë‹¤. ë˜í•œ ë¬´ë„í•¨ìˆ˜ ìµœì í™” ê¸°ë²•ì€ ê²½ì‚¬ ê¸°ë°˜ ë°©ë²•ê³¼ í•¨ê»˜ ì‚¬ìš©ë  ìˆ˜ë„ ìˆë‹¤.

<aside>

# 1. ì„œë¡ 

- ë¨¸ì‹ ëŸ¬ë‹ì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œì¤‘ í•˜ë‚˜ëŠ” ìµœì í™”ì´ë‹¤. ì´ëŠ” ì£¼ì–´ì§„ ë°ì´í„°ë¡œë¶€í„° ëª©ì í•¨ìˆ˜ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ í•™ìŠµí•˜ëŠ”ê²ƒì´ë‹¤.
- **ê¸°ìš¸ê¸°**
    - **1ì°¨ ìµœì í™” ê¸°ë²•(First-order optimization methods)**: í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•(Stochastic Gradient Descent, SGD) ê³„ì—´ì´ ëŒ€í‘œì ì´ë‹¤.
    - **ê³ ì°¨ ìµœì í™” ê¸°ë²•(High-order optimization methods)**: ë‰´í„´ë²•(Newtonâ€™s method)ì´ ì „í˜•ì ì¸ ì˜ˆì´ë‹¤. ê³¡ë¥ (curvature) ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ íƒìƒ‰ ë°©í–¥ì„ ë” íš¨ê³¼ì ìœ¼ë¡œ ë§Œë“ ë‹¤.
    - **ë¬´ë„í•¨ìˆ˜ ìµœì í™” ê¸°ë²•(Derivative-free optimization methods)**: ëª©ì  í•¨ìˆ˜ì˜ ë„í•¨ìˆ˜ê°€ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ê³„ì‚°í•˜ê¸° ì–´ë ¤ìš¸ ë•Œ ì‚¬ìš©ë˜ë©°, ì¢Œí‘œ í•˜ê°•ë²•(Coordinate Descent)ì´ ëŒ€í‘œì ì´ë‹¤.
- ì´ì¤‘ SGDì™€ ê°™ì€ 1ì°¨ ìµœì í™” ê¸°ë²•ë“¤ì€ ë¹ ë¥´ê²Œ ë°œì „ë˜ì–´ ì™”ë‹¤. ê·¸ëŸ¬ë‚˜ ì‚¬ìš©ìë“¤ì€ ì´ **ê¸°ë²•ë“¤ì˜ íŠ¹ì„±ì´ë‚˜ ì ìš© ë²”ìœ„ì— ì£¼ì˜ë¥¼ ê¸°ìš¸ì´ì§€ ì•Šê³ , ë¸”ë™ë°•ìŠ¤ ìµœì í™” ë„êµ¬ë¡œì„œ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸**ì— ê¸°ëŠ¥ì  ì ì¬ë ¥ì„ ì œí•œí•˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤. ê·¸ë˜ì„œ ì†Œê°œí•˜ê³ ì í•œë‹¤.
- **ê³ ì°¨ ìµœì í™” ê¸°ë²•ì€ 1ì°¨ ê¸°ë²•ë³´ë‹¤ ë” ë¹ ë¥¸ ìˆ˜ë ´ ì†ë„ë¥¼ ê°€ì§€ì§€ë§Œ í—¤ì‹  í–‰ë ¬ì˜ ì—­í–‰ë ¬ì„ ì €ì¥í•˜ê³  ê³„ì‹¼í•´ì•¼í•˜ëŠ” ì–´ë ¤ì›€**ì´ ìˆê³  ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ë°©ë²•ë“¤ì´ ê°œë°œë˜ì—ˆê³ , ëŒ€ë¶€ë¶„ **í•´ì‹ ì„ ê·¼ì‚¬í•˜ëŠ” ë°©ì‹ì„ ì±„íƒ**í•œë‹¤.
- ë¬´ë„í•¨ìˆ˜ ìµœì í™” ê¸°ë²•ì€ ë„í•¨ìˆ˜ê°€ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ê³„ì‚°ì´ ì–´ë ¤ìš¸ë•Œ ì‚¬ìš©ë˜ëŠ”ë° **ê²½í—˜ì  ê·œì¹™ì— ê¸°ë°˜í•œ íœ´ë¦¬ìŠ¤í‹± íƒìƒ‰ê³¼ í‘œë³¸ì„ ì´ìš©í•˜ì—¬ ëª©ì í•¨ìˆ˜ë¥¼ ê·¼ì‚¬**í•œë‹¤. ë˜í•œ ê²½ì‚¬ê¸°ë°˜ê¸°ë²•ê³¼ ê°™ì´ ì‚¬ìš©í•˜ê¸°ë„ í•œë‹¤.

### ìš”ì•½

- ë¨¸ì‹ ëŸ¬ë‹ì€ ë³¸ì§ˆì ìœ¼ë¡œ **ìµœì í™” ë¬¸ì œ**ë¡œ ë³¼ ìˆ˜ ìˆë‹¤.
- ìµœì í™”ëŠ” **1ì°¨Â·ê³ ì°¨Â·ë¬´ë„í•¨ìˆ˜** ì„¸ ê°€ì§€ë¡œ ë¶„ë¥˜ëœë‹¤.
- Convex ë¬¸ì œì—ì„œëŠ” ì „ì—­ ìµœì í•´ ë³´ì¥ì´ ê°€ëŠ¥í•˜ë‹¤.
- Non-convex ë¬¸ì œ(DNN, RL ë“±)ëŠ” ì§€ì—­ ìµœì ì Â·saddle pointë¡œ ìˆ˜ë ´í•˜ê¸° ì‰½ë‹¤.
- SGD ë‚¨ìš©ì€ ìœ„í—˜í•˜ë©°, ìƒí™©ë³„ ìµœì í™” ê¸°ë²• ì´í•´ì™€ ì„ íƒì´ í•„ìš”í•˜ë‹¤.

### í•µì‹¬

| êµ¬ë¶„                            | íŠ¹ì§•                                                        | ì¥ì                               | ë‹¨ì                                  | Convex / Non-convex ì ìš©ì„±                                            |
| ------------------------------- | ----------------------------------------------------------- | --------------------------------- | ------------------------------------ | --------------------------------------------------------------------- |
| 1ì°¨ ê¸°ë²• (First-order)          | Gradient ê¸°ë°˜ (SGD, Mini-batch ë“±)                          | ê³„ì‚° ë‹¨ìˆœ, ëŒ€ê·œëª¨ ë°ì´í„°ì— íš¨ìœ¨ì  | ìˆ˜ë ´ ì†ë„ ëŠë¦¼, í•™ìŠµë¥  íŠœë‹ í•„ìš”     | Convex: ì „ì—­ ìµœì í•´ ë³´ì¥ / Non-convex: ì§€ì—­ ìµœì í•´, saddle point ë¬¸ì œ |
| ê³ ì°¨ ê¸°ë²• (High-order)          | Hessian ë“± ê³¡ë¥ (curvature) ì •ë³´ í™œìš© (Newton, Quasi-Newton) | ë¹ ë¥¸ ìˆ˜ë ´, ë°©í–¥ì„± ìš°ìˆ˜            | Hessian ì—­í–‰ë ¬ ê³„ì‚°Â·ì €ì¥ ë¶€ë‹´        | Convex: ë¹ ë¥¸ ì „ì—­ ìˆ˜ë ´ / Non-convex: ê³„ì‚° ë¶€ë‹´ ì»¤ì„œ ì œí•œì             |
| ë¬´ë„í•¨ìˆ˜ ê¸°ë²• (Derivative-free) | Gradient í•„ìš” ì—†ìŒ (Coordinate descent, Heuristic search)   | ë¯¸ë¶„ ë¶ˆê°€ëŠ¥ ë¬¸ì œ í•´ê²°, ë‹¨ìˆœ êµ¬í˜„  | ì´ë¡ ì  ë³´ì¥ ì•½í•¨, ì „ì—­ ìµœì í™” ë¶ˆí™•ì‹¤ | Convex/Non-convex ëª¨ë‘ ê°€ëŠ¥í•˜ë‚˜ Heuristic ì˜ì¡´ì„± í¼                   |
</aside>

---

---

## ğŸ”¬ ì‹¤í—˜ê³¼ì •

### ğŸ“šÂ Machine Learning Formulated as Optimization

### ë²ˆì—­

1. ì›ë¬¸
    
    Almost all machine learning algorithms can be formulated as an optimization problem to find the extremum of an objective function. Building models and constructing reasonable objective functions are the first step in machine learning methods. With the determined objective function, appropriate numerical or analytical optimization methods are usually used to solve the optimization problem.
    
    According to the modeling purpose and the problem to be solved, machine learning algorithms can be divided into supervised learning, semi-supervised learning, unsupervised learning, and reinforcement learning. Particularly, supervised learning is further divided into the classification problem (e.g., sentence classification, image classification, etc.) and regression problem; unsupervised learning is divided into clustering and dimension reduction, among others.
    

---

1. ë²ˆì—­ë¬¸
    
    ê±°ì˜ ëª¨ë“  ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì€ **ëª©ì í•¨ìˆ˜(objective function)ì˜ ê·¹ê°’(extremum)** ì„ ì°¾ëŠ” ìµœì í™” ë¬¸ì œë¡œ ê³µì‹í™”(formulated)í•  ìˆ˜ ìˆë‹¤. ëª¨ë¸ì„ ì„¸ìš°ê³  í•©ë¦¬ì ì¸ ëª©ì í•¨ìˆ˜ë¥¼ êµ¬ì„±í•˜ëŠ” ê²ƒì´ ë¨¸ì‹ ëŸ¬ë‹ ë°©ë²•ì˜ ì²« ë²ˆì§¸ ë‹¨ê³„ì´ë‹¤. ëª©ì í•¨ìˆ˜ê°€ ê²°ì •ë˜ë©´, ì¼ë°˜ì ìœ¼ë¡œ ì ì ˆí•œ ìˆ˜ì¹˜ì (numerical) í˜¹ì€ í•´ì„ì (analytical) ìµœì í™” ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì´ ë¬¸ì œë¥¼ í•´ê²°í•œë‹¤.
    
    ëª¨ë¸ë§ ëª©ì ê³¼ í•´ê²°í•˜ë ¤ëŠ” ë¬¸ì œì— ë”°ë¼ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì€ í¬ê²Œ **ì§€ë„í•™ìŠµ(supervised learning), ì¤€ì§€ë„í•™ìŠµ(semi-supervised learning), ë¹„ì§€ë„í•™ìŠµ(unsupervised learning), ê°•í™”í•™ìŠµ(reinforcement learning)** ìœ¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆë‹¤. íŠ¹íˆ ì§€ë„í•™ìŠµì€ ë‹¤ì‹œ **ë¶„ë¥˜(classification)** ì™€ **íšŒê·€(regression)** ë¬¸ì œë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆìœ¼ë©°, ë¹„ì§€ë„í•™ìŠµì€ **êµ°ì§‘(clustering)** ê³¼ **ì°¨ì› ì¶•ì†Œ(dimension reduction)** ë“±ìœ¼ë¡œ ì„¸ë¶„ëœë‹¤.
    
2. ì›ë¬¸
    
    For supervised learning, the goal is to find an optimal mapping function f(x) to minimize the loss function of the training samples,
    
    minÎ¸ (1/N) Î£_{i=1}^N L(yi, f(xi, Î¸)),   (1)
    
    where N is the number of training samples, Î¸ is the parameter of the mapping function, xi is the feature vector of the ith sample, yi is the corresponding label, and L is the loss function.
    
    There are many kinds of loss functions in supervised learning, such as the square of Euclidean distance, cross-entropy, contrast loss, hinge loss, information gain and so on. For regression problems, the simplest way is using the square of Euclidean distance as the loss function, that is, minimizing square errors on training samples. But the generalization performance of this kind of empirical loss is not necessarily good. Another typical form is structured risk minimization, whose representative method is the support vector machine. On the objective function, regularization items are usually added to alleviate overfitting, e.g., in terms of L2 norm,
    
    minÎ¸ (1/N) Î£_{i=1}^N L(yi, f(xi, Î¸)) + Î» ||Î¸||â‚‚Â² ,   (2)
    
    where Î» is the compromise parameter, which can be determined through cross-validation.
    

---

1. ë²ˆì—­ë¬¸
    
    **ì§€ë„í•™ìŠµ(Supervised Learning)** ì—ì„œ ëª©í‘œëŠ” í›ˆë ¨ ìƒ˜í”Œì˜ ì†ì‹¤í•¨ìˆ˜(loss function)ë¥¼ ìµœì†Œí™”í•˜ëŠ” **ìµœì  ë§¤í•‘ í•¨ìˆ˜ f(x)** ë¥¼ ì°¾ëŠ” ê²ƒì´ë‹¤.
    
    ëª©ì í•¨ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ëœë‹¤:
    
    minÎ¸ (1/N) Î£_{i=1}^N L(yi, f(xi, Î¸)),   (1)
    
    ì—¬ê¸°ì„œ Nì€ í›ˆë ¨ ìƒ˜í”Œ ìˆ˜, Î¸ëŠ” ë§¤í•‘ í•¨ìˆ˜ì˜ íŒŒë¼ë¯¸í„°, xiëŠ” ië²ˆì§¸ ìƒ˜í”Œì˜ íŠ¹ì§• ë²¡í„°(feature vector), yiëŠ” í•´ë‹¹ ìƒ˜í”Œì˜ ë ˆì´ë¸”(label), Lì€ ì†ì‹¤í•¨ìˆ˜(loss function)ë¥¼ ì˜ë¯¸í•œë‹¤.
    
    ì§€ë„í•™ìŠµì—ì„œ ì‚¬ìš©ë˜ëŠ” ì†ì‹¤í•¨ìˆ˜ëŠ” ë‹¤ì–‘í•˜ë‹¤. ì˜ˆë¥¼ ë“¤ì–´ **ìœ í´ë¦¬ë“œ ê±°ë¦¬ ì œê³±(Square of Euclidean distance)**, **êµì°¨ ì—”íŠ¸ë¡œí”¼(Cross-Entropy)**, **ëŒ€ì¡° ì†ì‹¤(Contrast Loss)**, **íŒì§€ ì†ì‹¤(Hinge Loss)**, **ì •ë³´ ì´ë“(Information Gain)** ë“±ì´ ìˆë‹¤.
    
    - íšŒê·€(Regression) ë¬¸ì œì˜ ê²½ìš°, ê°€ì¥ ë‹¨ìˆœí•œ ë°©ì‹ì€ ìœ í´ë¦¬ë“œ ê±°ë¦¬ ì œê³±ì„ ì†ì‹¤í•¨ìˆ˜ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë©°, ì´ëŠ” í›ˆë ¨ ìƒ˜í”Œì— ëŒ€í•œ ì œê³± ì˜¤ì°¨ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê²ƒì´ë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ê²½í—˜ì  ì†ì‹¤ì€ ì¼ë°˜í™” ì„±ëŠ¥ì´ ë°˜ë“œì‹œ ì¢‹ë‹¤ê³  ë³´ì¥ë˜ì§€ ì•ŠëŠ”ë‹¤.
    - ë˜ ë‹¤ë¥¸ ì „í˜•ì ì¸ í˜•íƒœëŠ” **êµ¬ì¡°ì  ìœ„í—˜ ìµœì†Œí™”(Structured Risk Minimization, SRM)** ì´ë©°, ëŒ€í‘œì ì¸ ë°©ë²•ì€ **ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹ (Support Vector Machine, SVM)** ì´ë‹¤.
    
    ë˜í•œ ê³¼ì í•©(overfitting)ì„ ì™„í™”í•˜ê¸° ìœ„í•´ ëª©ì í•¨ìˆ˜ì— ë³´í†µ **ì •ê·œí™” í•­(regularization term)** ì„ ì¶”ê°€í•œë‹¤. ëŒ€í‘œì ìœ¼ë¡œ L2 ë…¸ë¦„ ê¸°ë°˜ ì •ê·œí™”ê°€ ìˆìœ¼ë©°, ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„ëœë‹¤:
    
    minÎ¸ (1/N) Î£_{i=1}^N L(yi, f(xi, Î¸)) + Î» ||Î¸||â‚‚Â² ,   (2)
    
    ì—¬ê¸°ì„œ Î»ëŠ” ê· í˜• íŒŒë¼ë¯¸í„°(compromise parameter)ë¡œ, ì¼ë°˜ì ìœ¼ë¡œ êµì°¨ê²€ì¦(cross-validation)ì„ í†µí•´ ê²°ì •ëœë‹¤.
    
    1. ì›ë¬¸
        
        Semi-supervised learning lies between supervised learning and unsupervised learning. In real applications, unlabeled samples are often more than labeled samples. Semi-supervised learning uses a small amount of labeled samples and a large number of unlabeled samples to construct an optimization problem. One type of semi-supervised learning is called semi-supervised support vector machine (S3VM). In S3VM, the constraint of maximizing margin is imposed not only on labeled samples but also on unlabeled samples.
        
        Another type of semi-supervised learning is graph-based semi-supervised learning, which regards all samples as vertices of a graph, and then edges are used to represent the similarity between samples. The assumption is that two similar samples are more likely to have the same label. The optimization objective function is to minimize the difference between labels of adjacent vertices.
        
    
    ---
    
    1. ë²ˆì—­ë¬¸
        
        **ì¤€ì§€ë„í•™ìŠµ(Semi-supervised Learning)** ì€ ì§€ë„í•™ìŠµê³¼ ë¹„ì§€ë„í•™ìŠµì˜ ì¤‘ê°„ì— ìœ„ì¹˜í•œë‹¤. ì‹¤ì œ ì‘ìš©ì—ì„œëŠ” **ë¼ë²¨ì´ ì—†ëŠ” ìƒ˜í”Œ(unlabeled samples)** ì´ ë¼ë²¨ì´ ìˆëŠ” ìƒ˜í”Œë³´ë‹¤ ë” ë§ì€ ê²½ìš°ê°€ í”í•˜ë‹¤. ì¤€ì§€ë„í•™ìŠµì€ ì†ŒëŸ‰ì˜ ë¼ë²¨ì´ ìˆëŠ” ìƒ˜í”Œê³¼ ë‹¤ìˆ˜ì˜ ë¼ë²¨ ì—†ëŠ” ìƒ˜í”Œì„ í•¨ê»˜ í™œìš©í•˜ì—¬ ìµœì í™” ë¬¸ì œë¥¼ êµ¬ì„±í•œë‹¤.
        
        ì¤€ì§€ë„í•™ìŠµì˜ í•œ ê°€ì§€ ìœ í˜•ì€ **ì¤€ì§€ë„ ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹ (Semi-supervised Support Vector Machine, S3VM)** ì´ë‹¤. S3VMì—ì„œëŠ” **ë§ˆì§„ ìµœëŒ€í™”(maximizing margin) ì œì•½ ì¡°ê±´**ì„ ë¼ë²¨ì´ ìˆëŠ” ìƒ˜í”Œë¿ë§Œ ì•„ë‹ˆë¼ ë¼ë²¨ ì—†ëŠ” ìƒ˜í”Œì—ë„ ì ìš©í•œë‹¤.
        
        ë‹¤ë¥¸ ìœ í˜•ìœ¼ë¡œëŠ” **ê·¸ë˜í”„ ê¸°ë°˜ ì¤€ì§€ë„í•™ìŠµ(Graph-based Semi-supervised Learning)** ì´ ìˆë‹¤. ì´ ë°©ë²•ì—ì„œëŠ” ëª¨ë“  ìƒ˜í”Œì„ ê·¸ë˜í”„ì˜ ì •ì (vertex)ìœ¼ë¡œ ë³´ê³ , ê°„ì„ (edge)ì€ ìƒ˜í”Œ ê°„ì˜ ìœ ì‚¬ì„±ì„ ë‚˜íƒ€ë‚¸ë‹¤. ê¸°ë³¸ ê°€ì •ì€ **ìœ ì‚¬í•œ ë‘ ìƒ˜í”Œì€ ê°™ì€ ë¼ë²¨ì„ ê°€ì§ˆ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤**ëŠ” ê²ƒì´ë‹¤. ìµœì í™” ëª©ì í•¨ìˆ˜ëŠ” ì¸ì ‘ ì •ì ì˜ ë¼ë²¨ ê°„ ì°¨ì´ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê²ƒì´ë‹¤.
        
    
    ---
    
    1. ë¬¸ (Section II-C ì „ì²´)
        
        Clustering algorithms [67], [82], [83], [84] divide a group of samples into multiple clusters ensuring that the differences between the samples in the same cluster are as small as possible, and samples in different clusters are as different as possible. The optimization problem for the k-means clustering algorithm is formulated as minimizing the following loss function:
        
        K
        
        min âˆ‘ âˆ‘ ||x âˆ’ Î¼k||â‚‚Â² ,   (2)
        
        Sk=1  xâˆˆSk
        
        where K is the number of clusters, x is the feature vector of samples, Î¼k is the center of cluster k, and Sk is the sample set of cluster k. The implication of this objective function is to make the sum of variances of all clusters as small as possible.
        
        The dimensionality reduction algorithm ensures that the original information from data is retained as much as possible after projecting them into the low-dimensional space. Principal component analysis (PCA) [85], [86], [87] is a typical algorithm of dimensionality reduction methods. The objective of PCA is formulated to minimize the reconstruction error as
        
        min Î£ ||xi âˆ’ xÌ‚i||â‚‚Â² ,   (5)
        
        N
        
        i=1
        
        where N represents the number of samples, xi is a D-dimensional vector, xÌ‚i is the reconstruction of xi. zi = {z1i, â€¦, zDâ€²i} is the projection of xi in Dâ€²-dimensional coordinates, D â‰« Dâ€². ej is the standard orthogonal basis under Dâ€²-dimensional coordinates.
        
        Another common optimization goal in probabilistic models is to find an optimal probability density function of p(x), which maximizes the logarithmic likelihood function (MLE) of the training samples,
        
        max Î£ ln p(xi ; Î¸).   (6)
        
        N
        
        i=1
        
        In the framework of Bayesian methods, some prior distributions are often assumed on parameter Î¸, which also has the effect of alleviating overfitting.
        
    
    ---
    
    1. ë²ˆì—­ë¬¸
        
        **í´ëŸ¬ìŠ¤í„°ë§ ì•Œê³ ë¦¬ì¦˜(Clustering algorithms)** [67], [82], [83], [84] ì€ ìƒ˜í”Œ ì§‘í•©ì„ ì—¬ëŸ¬ ê°œì˜ í´ëŸ¬ìŠ¤í„°ë¡œ ë‚˜ëˆ„ì–´, ë™ì¼ í´ëŸ¬ìŠ¤í„° ë‚´ì˜ ìƒ˜í”Œ ê°„ ì°¨ì´ê°€ ê°€ëŠ¥í•œ í•œ ì‘ê³ , ì„œë¡œ ë‹¤ë¥¸ í´ëŸ¬ìŠ¤í„° ê°„ ì°¨ì´ê°€ ê°€ëŠ¥í•œ í•œ í¬ë„ë¡ í•œë‹¤. k-means êµ°ì§‘í™”ì˜ ìµœì í™” ë¬¸ì œëŠ” ë‹¤ìŒì˜ ì†ì‹¤í•¨ìˆ˜ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê²ƒìœ¼ë¡œ ê³µì‹í™”ëœë‹¤:
        
        K
        
        min âˆ‘ âˆ‘ ||x âˆ’ Î¼k||â‚‚Â² ,   (2)
        
        k=1  xâˆˆSk
        
        ì—¬ê¸°ì„œ KëŠ” í´ëŸ¬ìŠ¤í„° ê°œìˆ˜, xëŠ” ìƒ˜í”Œì˜ íŠ¹ì§• ë²¡í„°, Î¼këŠ” kë²ˆì§¸ í´ëŸ¬ìŠ¤í„°ì˜ ì¤‘ì‹¬, SkëŠ” í´ëŸ¬ìŠ¤í„° kì— ì†í•˜ëŠ” ìƒ˜í”Œ ì§‘í•©ì´ë‹¤. ì´ ëª©ì í•¨ìˆ˜ì˜ ì˜ë¯¸ëŠ” **ëª¨ë“  í´ëŸ¬ìŠ¤í„°ì˜ ë¶„ì‚° í•©ì„ ìµœì†Œí™”**í•˜ëŠ” ê²ƒì´ë‹¤.
        
        **ì°¨ì› ì¶•ì†Œ(dimensionality reduction)** ì•Œê³ ë¦¬ì¦˜ì€ ë°ì´í„°ë¥¼ ì €ì°¨ì› ê³µê°„ìœ¼ë¡œ ì‚¬ì˜(projection)í–ˆì„ ë•Œ ì›ë˜ ì •ë³´ë¥¼ ìµœëŒ€í•œ ìœ ì§€í•˜ëŠ” ê²ƒì„ ë³´ì¥í•œë‹¤. **ì£¼ì„±ë¶„ ë¶„ì„(Principal Component Analysis, PCA)** [85], [86], [87] ì€ ì „í˜•ì ì¸ ì°¨ì› ì¶•ì†Œ ë°©ë²•ìœ¼ë¡œ, ëª©ì ì€ ìƒ˜í”Œì˜ ì¬êµ¬ì„± ì˜¤ì°¨(reconstruction error)ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê²ƒì´ë‹¤.
        
        min Î£ ||xi âˆ’ xÌ‚i||â‚‚Â² ,   (5)
        
        N
        
        i=1
        
        ì—¬ê¸°ì„œ Nì€ ìƒ˜í”Œ ìˆ˜, xiëŠ” Dì°¨ì› ë²¡í„°, xÌ‚iëŠ” xiì˜ ì¬êµ¬ì„±, zi = {z1i, â€¦, zDâ€²i} ëŠ” xiì˜ Dâ€² ì°¨ì› ê³µê°„ìœ¼ë¡œì˜ íˆ¬ì˜ ê°’ì´ë©°, D â‰« Dâ€² ì´ë‹¤. ejëŠ” Dâ€² ì°¨ì› ì¢Œí‘œê³„ì—ì„œì˜ í‘œì¤€ ì§êµ ê¸°ì €(orthogonal basis)ì´ë‹¤.
        
        **í™•ë¥ ì  ëª¨ë¸(probabilistic models)** ì—ì„œ ë˜ ë‹¤ë¥¸ ì¼ë°˜ì  ìµœì í™” ëª©í‘œëŠ” p(x)ì˜ ìµœì  í™•ë¥  ë°€ë„ í•¨ìˆ˜ë¥¼ ì°¾ëŠ” ê²ƒìœ¼ë¡œ, ì´ëŠ” í•™ìŠµ ìƒ˜í”Œì˜ ë¡œê·¸ìš°ë„(log-likelihood)ë¥¼ ìµœëŒ€í™”í•˜ëŠ” ë¬¸ì œì´ë‹¤:
        
        max Î£ ln p(xi ; Î¸).   (6)
        
        N
        
        i=1
        
        ë² ì´ì§€ì•ˆ ë°©ë²•ë¡ ì˜ í‹€ì—ì„œëŠ” ë§¤ê°œë³€ìˆ˜ Î¸ì— ëŒ€í•´ ì‚¬ì „ë¶„í¬(prior distribution)ë¥¼ ê°€ì •í•˜ë©°, ì´ëŠ” ê³¼ì í•©(overfitting)ì„ ì™„í™”í•˜ëŠ” íš¨ê³¼ë„ ê°€ì§„ë‹¤.
        
    
    **D. Optimization Problems in Reinforcement Learning**
    
    Reinforcement learning [42], [88], [89], unlike supervised learning and unsupervised learning, aims to find an optimal strategy function, whose output varies with the environment. For a deterministic strategy, the mapping function from state s to action a is the learning target. For an uncertain strategy, the probability of executing each action is the learning target. In each state, the action is determined by a = Ï€(s), where Ï€(s) is the policy function.
    
    The optimization problem in reinforcement learning can be formulated as maximizing the cumulative return after executing a series of actions which are determined by the policy function,
    
    VÏ€(s) = E [ Î£_{k=0}^âˆ Î³^k r_{t+k} | S_t = s ],   (7)
    
    where VÏ€(s) is the value function of state s under policy Ï€, r is the reward, and Î³ âˆˆ [0, 1] is the discount factor.
    
    maxÏ€ VÏ€(s)
    
    ---
    
    **E. Optimization for Machine Learning**
    
    Overall, the main steps of machine learning are to build a model hypothesis, define the objective function, and solve the maximum or minimum of the objective function to determine the parameters of the model. In these three vital steps, the first two steps are the modeling problems of machine learning, and the third step is to solve the desired model by optimization methods.
    
    ---
    
    1. ë²ˆì—­ë¬¸
    
    **D. ê°•í™”í•™ìŠµ(Reinforcement Learning)ì—ì„œì˜ ìµœì í™” ë¬¸ì œ**
    
    ê°•í™”í•™ìŠµ [42], [88], [89] ì€ ì§€ë„í•™ìŠµ(supervised learning), ë¹„ì§€ë„í•™ìŠµ(unsupervised learning)ê³¼ ë‹¬ë¦¬ **í™˜ê²½(environment)** ì— ë”°ë¼ ì¶œë ¥ì´ ë‹¬ë¼ì§€ëŠ” **ìµœì  ì „ëµ í•¨ìˆ˜(optimal strategy function)** ë¥¼ ì°¾ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.
    
    - ê²°ì •ì  ì „ëµ(deterministic strategy)ì˜ ê²½ìš°, ìƒíƒœ(state) sì—ì„œ í–‰ë™(action) aë¡œì˜ ë§¤í•‘ í•¨ìˆ˜ê°€ í•™ìŠµ ëŒ€ìƒì´ë‹¤.
    - ë¶ˆí™•ì‹¤í•œ ì „ëµ(stochastic strategy)ì˜ ê²½ìš°, ê° í–‰ë™ì´ ì‹¤í–‰ë  í™•ë¥ ì´ í•™ìŠµ ëŒ€ìƒì´ë‹¤.
    - ê° ìƒíƒœì—ì„œ í–‰ë™ì€ a = Ï€(s)ë¡œ ê²°ì •ë˜ë©°, Ï€(s)ëŠ” ì •ì±… í•¨ìˆ˜(policy function)ì´ë‹¤.
    
    ê°•í™”í•™ìŠµì˜ ìµœì í™” ë¬¸ì œëŠ” **ì •ì±… í•¨ìˆ˜ì— ì˜í•´ ê²°ì •ëœ ì¼ë ¨ì˜ í–‰ë™ì„ ìˆ˜í–‰í•œ ë’¤ ì–»ê²Œ ë˜ëŠ” ëˆ„ì  ë³´ìƒ(cumulative return)ì„ ìµœëŒ€í™”**í•˜ëŠ” ê²ƒìœ¼ë¡œ ê³µì‹í™”ëœë‹¤.
    
    VÏ€(s) = E [ Î£_{k=0}^âˆ Î³^k r_{t+k} | S_t = s ],   (7)
    
    ì—¬ê¸°ì„œ VÏ€(s)ëŠ” ì •ì±… Ï€ í•˜ì—ì„œ ìƒíƒœ sì˜ ê°€ì¹˜ í•¨ìˆ˜(value function), rì€ ë³´ìƒ(reward), Î³ âˆˆ [0, 1] ì€ í• ì¸ ì¸ì(discount factor)ì´ë‹¤.
    
    ìµœì¢… ëª©í‘œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤:
    
    maxÏ€ VÏ€(s)
    
    **E. ë¨¸ì‹ ëŸ¬ë‹ì—ì„œì˜ ìµœì í™”(Optimization for Machine Learning)**
    
    ì „ë°˜ì ìœ¼ë¡œ ë¨¸ì‹ ëŸ¬ë‹ì˜ ì£¼ìš” ë‹¨ê³„ëŠ” ì„¸ ê°€ì§€ì´ë‹¤.
    
    1. **ëª¨ë¸ ê°€ì„¤(model hypothesis) ìˆ˜ë¦½**
    2. **ëª©ì í•¨ìˆ˜(objective function) ì •ì˜**
    3. **ëª©ì í•¨ìˆ˜ì˜ ìµœëŒ“ê°’ ë˜ëŠ” ìµœì†Ÿê°’ì„ ì°¾ì•„ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ê²°ì •**
    
    ì´ ì„¸ ë‹¨ê³„ ì¤‘ ì²˜ìŒ ë‘ ë‹¨ê³„ëŠ” ë¨¸ì‹ ëŸ¬ë‹ì˜ ëª¨ë¸ë§ ë¬¸ì œì´ë©°, ì„¸ ë²ˆì§¸ ë‹¨ê³„ëŠ” **ìµœì í™” ë°©ë²•ì„ í†µí•´ ì›í•˜ëŠ” ëª¨ë¸ì„ í•´ê²°í•˜ëŠ” ê³¼ì •**ì´ë‹¤.
    

<aside>

# 2. Machine Learning Formulated as Optimization

- ë¨¸ì‹ ëŸ¬ë‹ ë¬¸ì œ : **ëª©ì í•¨ìˆ˜ì˜ ê·¹ê°’ì„ ì°¾ëŠ” ìµœì í™” ë¬¸ì œ**
    - ëª¨ë¸ì„ ì„¸ìš°ê³  ì ì í•œ ëª©ì í•¨ìˆ˜ë¥¼ êµ¬ì„±í•˜ëŠ” ê²ƒì´ ì¤‘ìš”
    - ì¼ë°˜ì ìœ¼ë¡œ ëª©ì í•¨ìˆ˜ê°€ ê²°ì •ë˜ë©´, ìˆ˜ì¹˜ì  í˜¹ì€ í•´ì„ì  ë°©ë²•ìœ¼ë¡œ ì´ë¥¼ í•´ê²°í•œë‹¤.
- **ë¨¸ì‹ ëŸ¬ë‹ íŒ¨ëŸ¬ë‹¤ì„ë³„ ìµœì í™”**
    - ì§€ë„í•™ìŠµ: ì†ì‹¤í•¨ìˆ˜(loss function)ë¥¼ ìµœì†Œí™” (ì˜ˆ: MSE, cross-entropy).
    - ì¤€ì§€ë„í•™ìŠµ: ë ˆì´ë¸” ì—†ëŠ” ë°ì´í„°ì— ì œì•½ì¡°ê±´(constraints) ì¶”ê°€ â†’ í˜¼í•© ìµœì í™” ë¬¸ì œ.
    - ë¹„ì§€ë„í•™ìŠµ: êµ°ì§‘í™”(K-means â†’ ê±°ë¦¬ ìµœì†Œí™”), ì°¨ì›ì¶•ì†Œ(PCA â†’ ì¬êµ¬ì„± ì˜¤ì°¨ ìµœì†Œí™”) ë“± ìµœì í™” ë¬¸ì œë¡œ ë³€í™˜.
    - ê°•í™”í•™ìŠµ: ëˆ„ì  ë³´ìƒ(cumulative reward)ì„ ìµœëŒ€í™”í•˜ëŠ” ì •ì±…(policy) í•™ìŠµ â†’ í™•ë¥ ì  ìµœì í™”.

<aside>

### Convex vs Non-convex

- **Convex vs Non-convex**
    - Convex: ì„ í˜• íšŒê·€, ë¡œì§€ìŠ¤í‹± íšŒê·€, SVMê³¼ ê°™ì€ ë¬¸ì œëŠ” Convex ìµœì í™”ë¡œ ìˆ˜ì‹í™” ê°€ëŠ¥. â†’ ì „ì—­ ìµœì í•´(global optimum) ì¡´ì¬.
    - Non-convex: ì‹¬ì¸µ ì‹ ê²½ë§(DNN), ê°•í™”í•™ìŠµ(RL) ë¬¸ì œëŠ” ëŒ€ë¶€ë¶„ ë¹„ë³¼ë¡(non-convex). â†’ ì§€ì—­ ìµœì í•´(local optimum) ë˜ëŠ” saddle pointì— ë¹ ì§ˆ ìœ„í—˜ ì¡´ì¬.
</aside>

### ìš”ì•½

- ë¨¸ì‹ ëŸ¬ë‹ì€ ë³¸ì§ˆì ìœ¼ë¡œ **ëª©ì í•¨ìˆ˜ ìµœì í™” ë¬¸ì œ**ë¡œ ìˆ˜ì‹í™”ëœë‹¤.
- ì§€ë„Â·ì¤€ì§€ë„Â·ë¹„ì§€ë„Â·ê°•í™”í•™ìŠµ ê°ê° ìµœì í™” ë¬¸ì œì˜ í˜•íƒœë¡œ ì •ì˜í•  ìˆ˜ ìˆë‹¤.
- Convex ë¬¸ì œ(ë¡œì§€ìŠ¤í‹± íšŒê·€, PCA ë“±)ëŠ” ì „ì—­ ìµœì í•´ ë³´ì¥.
- Non-convex ë¬¸ì œ(DNN, RL ë“±)ëŠ” ì§€ì—­ ìµœì ì Â·saddle point ë¬¸ì œ ì¡´ì¬.
- ë”°ë¼ì„œ MLì˜ ë°œì „ì€ ê³§ ë‹¤ì–‘í•œ **ìµœì í™” ê¸°ë²• ë°œì „**ê³¼ ì§ê²°ëœë‹¤.

### ì •ë¦¬

| í•™ìŠµ ìœ í˜•                         | ìµœì í™” ìˆ˜ì‹í™”                    | Convex / Non-convex ì„±ê²©                       | ëŒ€í‘œ ì˜ˆì‹œ                                 |
| --------------------------------- | -------------------------------- | ---------------------------------------------- | ----------------------------------------- |
| ì§€ë„í•™ìŠµ (Supervised)             | min (1/N) Î£ L(yi, f(xi; Î¸))      | Convex (ë¡œì§€ìŠ¤í‹± íšŒê·€, SVM) / Non-convex (DNN) | ë¶„ë¥˜(Classification), íšŒê·€(Regression)    |
| ì¤€ì§€ë„í•™ìŠµ (Semi-supervised)      | ë¼ë²¨ ì—†ëŠ” ë°ì´í„°ì— ì œì•½ì¡°ê±´ ì¶”ê°€ | Non-convex í˜¼í•© ë¬¸ì œ å¤š                        | S3VM, Graph-based SSL                     |
| ë¹„ì§€ë„í•™ìŠµ (Unsupervised)         | K-means: min Î£                   |                                                | x - Î¼                                     |
| ê°•í™”í•™ìŠµ (Reinforcement Learning) | max E[Î£ Î³^k r_t+k]               | Non-convex (ì •ì±…ê³µê°„ íƒìƒ‰)                     | Q-learning, Policy Gradient, Actor-Critic |

## 2.1. Optimization Problems in Supervised Learning

![image.png](A%20Survey%20of%20Optimization%20Methods%20from%20a%20Machine%20Le%2025ca9b246de180a3838bcfa8d6ca3088/image.png)

- ì§€ë„í•™ìŠµì—ì„œì˜ í›ˆë ¨ ëª©í‘œ : í›ˆë ¨ ìƒ˜í”Œì˜ ì†ì‹¤í•¨ìˆ˜ë¥¼ ìµœì†Œí™”í•˜ëŠ” ìµœì  ë§¤í•‘ í•¨ìˆ˜ë¥¼ ì°¾ëŠ”ê²ƒ
- **ìœ í´ë¦¬ë“œ ê±°ë¦¬ ì œê³±(Square of Euclidean distance)**, **êµì°¨ ì—”íŠ¸ë¡œí”¼(Cross-Entropy)**, **ëŒ€ì¡° ì†ì‹¤(Contrast Loss)**, **íŒì§€ ì†ì‹¤(Hinge Loss)**, **ì •ë³´ ì´ë“(Information Gain)**
    - íšŒê·€(Regression) ë¬¸ì œì˜ ê²½ìš°, ê°€ì¥ ë‹¨ìˆœí•œ ë°©ì‹ì€ ìœ í´ë¦¬ë“œ ê±°ë¦¬ ì œê³±ì„ ì†ì‹¤í•¨ìˆ˜ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë©°, ì´ëŠ” í›ˆë ¨ ìƒ˜í”Œì— ëŒ€í•œ ì œê³± ì˜¤ì°¨ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê²ƒì´ë‹¤. ê²½í—˜ì  ì†ì‹¤ì€ ì¼ë°˜í™” ì„±ëŠ¥ì´ ë°˜ë“œì‹œ ì¢‹ë‹¤ê³  ë³´ì¥ë˜ì§€ ì•ŠëŠ”ë‹¤.
    - ë˜ ë‹¤ë¥¸ ì „í˜•ì ì¸ í˜•íƒœëŠ” **êµ¬ì¡°ì  ìœ„í—˜ ìµœì†Œí™”(Structured Risk Minimization, SRM)** ì´ë©°, ëŒ€í‘œì ì¸ ë°©ë²•ì€ **ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹ (Support Vector Machine, SVM)** ì´ë‹¤.
- ê³¼ì í™” ë°©ì§€ë¥¼ ìœ„í•´ **ì •ê·œí™”í•­**ì„ ì¶”ê°€í•˜ê¸°ë„ í•œë‹¤. ì•„ë˜ëŠ” L2Normì´ë‹¤.

![image.png](A%20Survey%20of%20Optimization%20Methods%20from%20a%20Machine%20Le%2025ca9b246de180a3838bcfa8d6ca3088/image%201.png)

### ìš”ì•½

- ì§€ë„í•™ìŠµì€ ì†ì‹¤í•¨ìˆ˜ë¥¼ ìµœì†Œí™”í•˜ëŠ” **f(x; Î¸)** í•™ìŠµ ë¬¸ì œë¡œ ì •ì˜ëœë‹¤.
- ì†ì‹¤í•¨ìˆ˜ ì˜ˆì‹œ: MSE, Cross-entropy, Hinge loss ë“±.
- Convex ì†ì‹¤í•¨ìˆ˜ëŠ” ì „ì—­ ìµœì í•´ ë³´ì¥, Non-convex(DNN)ëŠ” ì§€ì—­ ìµœì í•´ ë¬¸ì œ ì¡´ì¬.
- ì •ê·œí™” í•­(L2 norm ë“±)ì€ ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•´ ìì£¼ ì¶”ê°€ëœë‹¤.
- Î» ê°’ì€ êµì°¨ê²€ì¦ìœ¼ë¡œ ê²°ì •í•˜ë©°, ëª¨ë¸ì˜ ë³µì¡ë„ì™€ ì¼ë°˜í™” ì„±ëŠ¥ì„ ì¡°ì ˆí•œë‹¤.

### ì •ë¦¬

| ìš”ì†Œ                         | ì„¤ëª…                                    | Convex ì—¬ë¶€               |
| ---------------------------- | --------------------------------------- | ------------------------- |
| ê¸°ë³¸ ëª©ì í•¨ìˆ˜                | minÎ¸ (1/N) Î£ L(yi, f(xi; Î¸))            | ì†ì‹¤í•¨ìˆ˜ ì¢…ë¥˜ì— ë”°ë¼ ë‹¤ë¦„ |
| ì†ì‹¤í•¨ìˆ˜ ì˜ˆì‹œ                | L2 loss, Cross-entropy, Hinge loss      | ëŒ€ë¶€ë¶„ Convex             |
| Structured Risk Minimization | ì¼ë°˜í™” ì˜¤ë¥˜ ìµœì†Œí™”, SVM ëŒ€í‘œ            | Convex                    |
| ì •ê·œí™” í•­                    | Î»                                       |                           |
| ì‹¬ì¸µ ì‹ ê²½ë§                  | ëª©ì í•¨ìˆ˜ ë¹„ì„ í˜•Â·ë³µì¡ â†’ ì§€ì—­ ìµœì ì  ë¬¸ì œ | Non-convex                |

## 2.2. Optimization Problems in Semi-supervised Learning

![image.png](A%20Survey%20of%20Optimization%20Methods%20from%20a%20Machine%20Le%2025ca9b246de180a3838bcfa8d6ca3088/image%202.png)

ë‹¤ë¥¸ ìœ í˜•ìœ¼ë¡œëŠ” **ê·¸ë˜í”„ ê¸°ë°˜ ì¤€ì§€ë„í•™ìŠµ(Graph-based Semi-supervised Learning)** ì´ ìˆë‹¤. ì´ ë°©ë²•ì—ì„œëŠ” ëª¨ë“  ìƒ˜í”Œì„ ê·¸ë˜í”„ì˜ ì •ì (vertex)ìœ¼ë¡œ ë³´ê³ , ê°„ì„ (edge)ì€ ìƒ˜í”Œ ê°„ì˜ ìœ ì‚¬ì„±ì„ ë‚˜íƒ€ë‚¸ë‹¤. ê¸°ë³¸ ê°€ì •ì€ **ìœ ì‚¬í•œ ë‘ ìƒ˜í”Œì€ ê°™ì€ ë¼ë²¨ì„ ê°€ì§ˆ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤**ëŠ” ê²ƒì´ë‹¤. ìµœì í™” ëª©ì í•¨ìˆ˜ëŠ” ì¸ì ‘ ì •ì ì˜ ë¼ë²¨ ê°„ ì°¨ì´ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê²ƒì´ë‹¤.

- ì¤€ì§€ë„í•™ìŠµì—ì„œì˜ í›ˆë ¨ ëª©í‘œ : ë¼ë²¨ì´ ìˆëŠ” ì†ŒëŸ‰ì˜ ë¼ë²¨ê³¼ ë¼ë²¨ì´ ì—†ëŠ” ë‹¤ìˆ˜ì˜ ë¼ë²¨ì„ í™œìš©í•˜ì—¬ ìµœì í™” ë¬¸ì œë¥¼ êµ¬ì„±
- **ì¤€ì§€ë„ ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹ (Semi-supervised Support Vector Machine, S3VM)**
    - **ë§ˆì§„ ìµœëŒ€í™”(maximizing margin) ì œì•½ ì¡°ê±´ ë“±ìœ¼ë¡œ ë¼ë²¨ê³¼ ë¹„ë¼ë²¨ì— ë‘˜ ë‹¤ ì ìš©í•œë‹¤.**
- **ê·¸ë˜í”„ ê¸°ë°˜ ì¤€ì§€ë„í•™ìŠµ(Graph-based Semi-supervised Learning) : ëª¨ë“  ìƒ˜í”Œì„ ì •ì ìœ¼ë¡œë³´ê³ , ìœ ì‚¬í•œ ë‘ ìƒ˜í”Œì€ ê°™ì€ ë¼ë²¨ì„ ê°€ì§ˆ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤**ëŠ” ê²ƒ - ë¼ë²¨ ê°„ ì°¨ì´ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê²ƒì´ë‹¤.

<aside>

### SRM

- ê²½í—˜ì  ìœ„í—˜ (Empirical Risk) : ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ì—ì„œ ì–¼ë§ˆë‚˜ ë§ì´ í‹€ë¦¬ëŠ”ê°€
- êµ¬ì¡°ì  ìœ„í—˜ (Structural Risk) : ëª¨ë¸ì˜ ë³µì¡ë„ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ìœ„í—˜, ê³¼ì í•©ì´ ë°œìƒí•  ìœ„í—˜ì´ ì»¤ì§

SRMì€ ë‘ ê°€ì§€ ìœ„í—˜ì˜ í•©ì„ ìµœì†Œí™”í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.

- ìµœì¢…ìœ„í—˜ (ì¼ë°˜í™” ì˜¤ë¥˜) â‰¤ ê²½í—˜ì  ìœ„í—˜ + êµ¬ì¡°ì  ìœ„í—˜(ëª¨ë¸ ë³µì¡ë„ì— ë”°ë¥¸ íŒ¨ë„í‹°)
    - ì •ê·œí™” : íŒ¨ë„í‹° í•­ì„ ì¶”ê°€í•˜ëŠ” ê¸°ë²•
    - SVM : SRM ì›ë¦¬ë¥¼ ê°€ì¥ ì˜ êµ¬í˜„í•œ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ë§ˆì§„ì„ ìµœëŒ€í™” í•˜ë ¤ê³ í•¨.
</aside>

### ìš”ì•½

- ì¤€ì§€ë„í•™ìŠµì€ **ë¼ë²¨ ë¶€ì¡± ë¬¸ì œ** í•´ê²°ì„ ìœ„í•´ ë¼ë²¨ ì—†ëŠ” ë°ì´í„°ê¹Œì§€ ìµœì í™”ì— í¬í•¨í•œë‹¤.
- S3VMì€ ë¼ë²¨ ì—†ëŠ” ìƒ˜í”Œì—ë„ ë§ˆì§„ ìµœëŒ€í™” ì ìš© â†’ **Non-convex ìµœì í™”**.
- Graph-based SSLì€ ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¸ì ‘ ìƒ˜í”Œ ë¼ë²¨ ì°¨ì´ë¥¼ ìµœì†Œí™” â†’ **Convex ê°€ëŠ¥**.
- ì¤€ì§€ë„í•™ìŠµì˜ ëª©ì í•¨ìˆ˜ëŠ” â€œì§€ë„ ì†ì‹¤ + ë¹„ì§€ë„ ì œì•½ì¡°ê±´â€ì˜ í˜¼í•©.
- ì‹¤ì œ ì‘ìš©ì—ì„œ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ í•„ìˆ˜ì ì¸ ë°©ë²•ë¡ ì´ë‹¤.

### ì¤‘ìš”

| ë°©ë²•            | ìµœì í™” ê³µì‹í™”                                         | Convex ì—¬ë¶€ | íŠ¹ì§•                                           |
| --------------- | ----------------------------------------------------- | ----------- | ---------------------------------------------- |
| S3VM            | ë¼ë²¨ ìˆëŠ” ìƒ˜í”Œ + ì—†ëŠ” ìƒ˜í”Œ ëª¨ë‘ ë§ˆì§„ ìµœëŒ€í™”           | Non-convex  | ë¼ë²¨ ë¶€ì¡± ìƒí™©ì—ì„œ ê°•ë ¥, í•˜ì§€ë§Œ ê³„ì‚° ë³µì¡      |
| Graph-based SSL | ê·¸ë˜í”„ ë¼í”Œë¼ì‹œì•ˆ ì •ê·œí™” â†’ ì¸ì ‘ ë…¸ë“œ ë¼ë²¨ ì°¨ì´ ìµœì†Œí™” | Convex ê°€ëŠ¥ | ìœ ì‚¬ë„ ê¸°ë°˜, Semi-supervised Clusteringì— ì í•© |
| ê³µí†µì           | ì§€ë„ ì†ì‹¤ + ë¹„ì§€ë„ ì œì•½ ê²°í•©                          | í˜¼í•©        | ë¼ë²¨ ì—†ëŠ” ë°ì´í„° í™œìš©ìœ¼ë¡œ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ     |

## 2.3. Optimization Problems in Unsupervised Learning

- ë¹„ì§€ë„ í•™ìŠµ ëª©í‘œ : ë°ì´í„°ë¡œë¶€í„° **ìˆ¨ê²¨ì§„ êµ¬ì¡°**ë¥¼ ë°œê²¬í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•¨
    - **êµ°ì§‘í™” :** ëŒ€í‘œì ì¸ ì˜ˆ, k-means
        
        ![image.png](A%20Survey%20of%20Optimization%20Methods%20from%20a%20Machine%20Le%2025ca9b246de180a3838bcfa8d6ca3088/image%203.png)
        
    - **PCA :** ì°¨ì›ì¶•ì†Œ - ì¬êµ¬ì„± ì˜¤ì°¨ë¥¼ ìµœì†Œí™”
        
        ![image.png](A%20Survey%20of%20Optimization%20Methods%20from%20a%20Machine%20Le%2025ca9b246de180a3838bcfa8d6ca3088/image%204.png)
        
    - Bayesian BLE : í™•ë¥  ë°€ë„ í•¨ìˆ˜ë¥¼ ì°¾ëŠ”ê²ƒìœ¼ë¡œ ìš°ë„í•¨ìˆ˜ë¥¼ ìµœëŒ€í™”í•˜ëŠ” ë¬¸ì œ
1. **Clustering (k-means)**
    - ëª©ì : ê° ìƒ˜í”Œì´ ì†í•œ í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ê³¼ì˜ ì œê³±ê±°ë¦¬ í•© ìµœì†Œí™”.
    - Convex ì—¬ë¶€: **Non-convex** (í´ëŸ¬ìŠ¤í„° í• ë‹¹ì´ ì´ì‚°ì ).
    - ë¬¸ì œ: ì´ˆê¸°ê°’ì— ë”°ë¼ ì§€ì—­ ìµœì í•´(local optimum)ì— ë¨¸ë¬´ë¦„.
2. **ì°¨ì› ì¶•ì†Œ (PCA)**
    - ëª©ì : ì› ë°ì´í„°ì™€ ì¬êµ¬ì„± ë°ì´í„° ê°„ ì˜¤ì°¨ ìµœì†Œí™”.
    - Convex ì—¬ë¶€: **Convex** (ê³ ìœ ë²¡í„° ë¶„í•´ ê¸°ë°˜, ì „ì—­ ìµœì í•´ ë³´ì¥).
    - ë°ì´í„° ë¶„ì‚°ì„ ìµœëŒ€ ë³´ì¡´í•˜ëŠ” ì €ì°¨ì› íˆ¬ì˜ì„ ì°¾ëŠ” ìˆ˜í•™ì ìœ¼ë¡œ ì•ˆì •ëœ ë°©ë²•.
3. **í™•ë¥ ì  ëª¨ë¸ (MLE, Bayesian)**
    - ëª©ì : ê´€ì¸¡ ë°ì´í„°ì— ëŒ€í•œ Likelihood ìµœëŒ€í™”.
    - Convex ì—¬ë¶€: **Non-convex** (íŠ¹íˆ GMM, VAE, GAN ë“±).
    - Bayesian ì ‘ê·¼: íŒŒë¼ë¯¸í„°ì— Prior ë¶„í¬ë¥¼ ë¶€ì—¬ â†’ ê³¼ì í•© ì™„í™”.
    - ì‹¤ì œë¡œëŠ” EM ì•Œê³ ë¦¬ì¦˜, ë³€ë¶„ ì¶”ë¡ , MCMC ë“±ì´ ë™ì›ë¨.

### ìš”ì•½

- ë¹„ì§€ë„í•™ìŠµì€ ë°ì´í„°ì˜ ìˆ¨ê²¨ì§„ êµ¬ì¡°ë¥¼ ì°¾ëŠ” ìµœì í™” ë¬¸ì œë¡œ ì •ì˜ëœë‹¤.
- k-meansëŠ” í´ëŸ¬ìŠ¤í„° ë¶„ì‚° ìµœì†Œí™” â†’ **Non-convex**, ì´ˆê¸°í™” ë¯¼ê°.
- PCAëŠ” ì¬êµ¬ì„± ì˜¤ì°¨ ìµœì†Œí™” â†’ **Convex**, ì „ì—­ ìµœì í•´ ê°€ëŠ¥.
- í™•ë¥ ì  ëª¨ë¸ì€ ë¡œê·¸ìš°ë„ ìµœëŒ€í™” â†’ **Non-convex**, ê·¼ì‚¬ì¶”ë¡  í•„ìš”.
- Bayesian ì ‘ê·¼ì€ Priorë¥¼ ì¶”ê°€í•´ ê³¼ì í•© ì™„í™” ê°€ëŠ¥.

### ì •ë¦¬

| ë°©ë²•              | ìµœì í™” ë¬¸ì œ              | Convex ì—¬ë¶€ | íŠ¹ì§•                           |
| ----------------- | ------------------------ | ----------- | ------------------------------ |
| k-means           | min Î£                    |             | x âˆ’ Î¼k                         |
| PCA               | min Î£                    |             | xi âˆ’ xÌ‚i                        |
| í™•ë¥ ì  ëª¨ë¸ (MLE) | max Î£ ln p(xi ; Î¸)       | Non-convex  | ê·¼ì‚¬ì¶”ë¡  í•„ìš”, EM/VI/MCMC í™œìš© |
| Bayesian í™•ì¥     | max Posterior with prior | Non-convex  | Priorë¡œ ê³¼ì í•© ì™„í™” ê°€ëŠ¥       |

# 2.4. ê°•í™”í•™ìŠµ

- **í™˜ê²½ì— ë”°ë¼ ì¶œë ¥ì´ ë‹¬ë¼ì§€ëŠ” ìµœì  ì „ëµí•¨ìˆ˜ë¥¼ ì°¾ëŠ”ê²ƒ  â†’ ëˆ„ì  ë³´ìƒ ìµœëŒ€í™”**
    - ê²°ì • ì •ì±… : ìƒíƒœì—ì„œ í–‰ë™ìœ¼ë¡œ í•¨ìˆ˜ë¥¼ ë§¤í•‘, í•™ìŠµ ëŒ€ìƒ
    - í™•ë¥ ì  ì •ì±… : í–‰ë™ì´ ì‹¤í–‰ë  í™•ë¥ ì´ ëŒ€ìƒ

![image.png](A%20Survey%20of%20Optimization%20Methods%20from%20a%20Machine%20Le%2025ca9b246de180a3838bcfa8d6ca3088/image%205.png)

### ìš”ì•½

- ê°•í™”í•™ìŠµì€ í™˜ê²½ê³¼ ìƒí˜¸ì‘ìš©í•˜ë©° **ì •ì±…(policy) ìµœì í™”**ë¥¼ ìˆ˜í–‰í•œë‹¤.
- ëª©ì ì€ ìƒíƒœ ê°€ì¹˜ í•¨ìˆ˜ VÏ€(s)ì˜ ê¸°ëŒ€ ëˆ„ì  ë³´ìƒì„ ìµœëŒ€í™”í•˜ëŠ” ê²ƒ.
- ë‹¨ìˆœí•œ ê²½ìš° Convex ê°€ëŠ¥í•˜ë‚˜, Deep RLì€ **Non-convex** ìµœì í™” ë¬¸ì œ.
- ë¨¸ì‹ ëŸ¬ë‹ì˜ ì„¸ ë‹¨ê³„ëŠ” ëª¨ë¸ ê°€ì„¤ ì„¤ì • â†’ ëª©ì í•¨ìˆ˜ ì •ì˜ â†’ ìµœì í™” ìˆ˜í–‰.
- ì´ ì¤‘ ìµœì í™”ê°€ ì‹¤ì œ í•™ìŠµì„ ë‹´ë‹¹í•˜ë©°, ML ë°œì „ì˜ í•µì‹¬ ë™ë ¥ì´ë‹¤.

### ì •ë¦¬

 

| êµ¬ë¶„          | ìµœì í™” ë¬¸ì œ                        | Convex ì—¬ë¶€                   | íŠ¹ì§•                               |
| ------------- | ---------------------------------- | ----------------------------- | ---------------------------------- |
| ê°•í™”í•™ìŠµ (RL) | maxÏ€ VÏ€(s) = E[Î£ Î³^k r]            | ëŒ€ë¶€ë¶„ Non-convex             | ì •ì±… í•¨ìˆ˜ ìµœì í™”, ëˆ„ì  ë³´ìƒ ìµœëŒ€í™” |
| ì§€ë„/ë¹„ì§€ë„   | min/max ëª©ì í•¨ìˆ˜ (ì†ì‹¤, ìš°ë„ ë“±)   | Convex & Non-convex í˜¼ì¬      | ë°ì´í„° ê¸°ë°˜ í•™ìŠµ                   |
| ë¨¸ì‹ ëŸ¬ë‹ ì „ë°˜ | ëª¨ë¸ ê°€ì„¤ â†’ ëª©ì í•¨ìˆ˜ ì •ì˜ â†’ ìµœì í™” | ë‹¨ê³„ 1Â·2ëŠ” ëª¨ë¸ë§, 3ì€ ìµœì í™” | ìµœì í™”ê°€ ì‹¤ì§ˆì  í•™ìŠµì˜ í•µì‹¬        |
</aside>

### ğŸ“šÂ (ì˜ˆì‹œ)

### ë²ˆì—­

<aside>

</aside>

### ğŸ“šÂ (ì˜ˆì‹œ)

### ë²ˆì—­

<aside>

</aside>

### ğŸ“šÂ (ì˜ˆì‹œ)

### ë²ˆì—­

<aside>

</aside>

### ğŸ“šÂ (ì˜ˆì‹œ)

### ë²ˆì—­

<aside>

</aside>

### ğŸ“šÂ (ì˜ˆì‹œ)

### ë²ˆì—­

<aside>

</aside>

### ğŸ“šÂ (ì˜ˆì‹œ)

### ë²ˆì—­

<aside>

</aside>

---